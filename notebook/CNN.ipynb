{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3927ffd3-5c0a-49fb-ab59-ad54a5701f9e",
   "metadata": {},
   "source": [
    "### Loading necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f68d4db-5208-4d16-84ea-0485517c5c05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T16:09:23.752878Z",
     "iopub.status.busy": "2025-03-21T16:09:23.751968Z",
     "iopub.status.idle": "2025-03-21T16:09:24.163140Z",
     "shell.execute_reply": "2025-03-21T16:09:24.161239Z",
     "shell.execute_reply.started": "2025-03-21T16:09:23.752820Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdf57b4-8827-4ed0-b5a8-8f80812da2c1",
   "metadata": {},
   "source": [
    "### Defining files' path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80a3edbe-0cdf-4e73-8779-481d600b34b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T17:27:30.223780Z",
     "iopub.status.busy": "2025-03-21T17:27:30.219334Z",
     "iopub.status.idle": "2025-03-21T17:27:30.245292Z",
     "shell.execute_reply": "2025-03-21T17:27:30.243756Z",
     "shell.execute_reply.started": "2025-03-21T17:27:30.223675Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = '../data/'\n",
    "model_dir = '../model/'\n",
    "\n",
    "dir_ = os.listdir(data_dir)\n",
    "\n",
    "model_file = model_dir + 'CNN.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1d76610-4631-4f9b-9a02-bb203f75e65d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T17:27:33.135988Z",
     "iopub.status.busy": "2025-03-21T17:27:33.135454Z",
     "iopub.status.idle": "2025-03-21T17:27:33.159759Z",
     "shell.execute_reply": "2025-03-21T17:27:33.156566Z",
     "shell.execute_reply.started": "2025-03-21T17:27:33.135940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['valid', 'train', 'test', 'images2predict']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba270b84-90d5-4bc7-b5de-9ae213d942e9",
   "metadata": {},
   "source": [
    "### Retrieving directories list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74a870c3-f8f8-4e47-a3e9-031da2e8cb89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T17:30:48.842330Z",
     "iopub.status.busy": "2025-03-21T17:30:48.841608Z",
     "iopub.status.idle": "2025-03-21T17:30:48.858907Z",
     "shell.execute_reply": "2025-03-21T17:30:48.857539Z",
     "shell.execute_reply.started": "2025-03-21T17:30:48.842271Z"
    }
   },
   "outputs": [],
   "source": [
    "all_dir = dict.fromkeys(dir_)\n",
    "\n",
    "for d in dir_ :\n",
    "    all_dir[d] = glob.glob(data_dir+d+'/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59146fb6-f19b-4776-81a9-734ff255347c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T17:31:44.821382Z",
     "iopub.status.busy": "2025-03-21T17:31:44.818885Z",
     "iopub.status.idle": "2025-03-21T17:31:44.836700Z",
     "shell.execute_reply": "2025-03-21T17:31:44.833040Z",
     "shell.execute_reply.started": "2025-03-21T17:31:44.821252Z"
    }
   },
   "source": [
    "### Retrieving data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "432de302-d0e5-4522-bd10-c50651661b66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T18:22:06.404810Z",
     "iopub.status.busy": "2025-03-21T18:22:06.404274Z",
     "iopub.status.idle": "2025-03-21T18:22:06.440377Z",
     "shell.execute_reply": "2025-03-21T18:22:06.439526Z",
     "shell.execute_reply.started": "2025-03-21T18:22:06.404765Z"
    }
   },
   "outputs": [],
   "source": [
    "files = dict.fromkeys(dir_)\n",
    "\n",
    "for key in dict.fromkeys(dir_) :\n",
    "    files[key] = []\n",
    "    \n",
    "    for d in range(len(all_dir[key])) :\n",
    "\n",
    "        if key != 'images2predict' :\n",
    "            files[key].extend(glob.glob(all_dir[key][d]+'/*.jpg'))\n",
    "        else :\n",
    "            files[key].append(all_dir[key][d])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9561d7d6-c8a5-44e3-b5a5-afcfd2dd9031",
   "metadata": {},
   "source": [
    "### Investigate dataset resolution distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "11e4198e-9f83-4574-aec3-b5d2e04dc4c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T18:22:37.774817Z",
     "iopub.status.busy": "2025-03-21T18:22:37.774293Z",
     "iopub.status.idle": "2025-03-21T18:22:41.625612Z",
     "shell.execute_reply": "2025-03-21T18:22:41.624614Z",
     "shell.execute_reply.started": "2025-03-21T18:22:37.774772Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average dimensions for images in the valid folder is (224, 224, 3)\n",
      "The maximum dimensions for images in the valid folder is (224, 224, 3)\n",
      "The mimimum dimensions for images in the valid folder is (224, 224, 3)\n",
      "The median dimensions for images in the valid folder is (np.float64(224.0), np.float64(224.0), np.float64(3.0))\n",
      "The 25th percentile dimensions for images in the valid folder is (np.float64(224.0), np.float64(224.0), np.float64(3.0))\n",
      "The 75th percentile dimensions for images in the valid folder is (np.float64(224.0), np.float64(224.0), np.float64(3.0))\n",
      "The 90th percentile dimensions for images in the valid folder is (np.float64(224.0), np.float64(224.0), np.float64(3.0))\n",
      "\n",
      "\n",
      "The average dimensions for images in the train folder is (224, 224, 3)\n",
      "The maximum dimensions for images in the train folder is (224, 224, 3)\n",
      "The mimimum dimensions for images in the train folder is (224, 224, 3)\n",
      "The median dimensions for images in the train folder is (np.float64(224.0), np.float64(224.0), np.float64(3.0))\n",
      "The 25th percentile dimensions for images in the train folder is (np.float64(224.0), np.float64(224.0), np.float64(3.0))\n",
      "The 75th percentile dimensions for images in the train folder is (np.float64(224.0), np.float64(224.0), np.float64(3.0))\n",
      "The 90th percentile dimensions for images in the train folder is (np.float64(224.0), np.float64(224.0), np.float64(3.0))\n",
      "\n",
      "\n",
      "The average dimensions for images in the test folder is (224, 224, 3)\n",
      "The maximum dimensions for images in the test folder is (224, 224, 3)\n",
      "The mimimum dimensions for images in the test folder is (224, 224, 3)\n",
      "The median dimensions for images in the test folder is (np.float64(224.0), np.float64(224.0), np.float64(3.0))\n",
      "The 25th percentile dimensions for images in the test folder is (np.float64(224.0), np.float64(224.0), np.float64(3.0))\n",
      "The 75th percentile dimensions for images in the test folder is (np.float64(224.0), np.float64(224.0), np.float64(3.0))\n",
      "The 90th percentile dimensions for images in the test folder is (np.float64(224.0), np.float64(224.0), np.float64(3.0))\n",
      "\n",
      "\n",
      "The average dimensions for images in the images2predict folder is (224, 224, 3)\n",
      "The maximum dimensions for images in the images2predict folder is (224, 224, 3)\n",
      "The mimimum dimensions for images in the images2predict folder is (224, 224, 3)\n",
      "The median dimensions for images in the images2predict folder is (np.float64(224.0), np.float64(224.0), np.float64(3.0))\n",
      "The 25th percentile dimensions for images in the images2predict folder is (np.float64(224.0), np.float64(224.0), np.float64(3.0))\n",
      "The 75th percentile dimensions for images in the images2predict folder is (np.float64(224.0), np.float64(224.0), np.float64(3.0))\n",
      "The 90th percentile dimensions for images in the images2predict folder is (np.float64(224.0), np.float64(224.0), np.float64(3.0))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in dict.fromkeys(dir_) :\n",
    "    # Empty shape list\n",
    "    shape = []\n",
    "\n",
    "    # Empty image list\n",
    "    image_un = []\n",
    "\n",
    "    for file in files[key] :\n",
    "        # Read image file\n",
    "        image = plt.imread(file)\n",
    "\n",
    "        # Add image to image list\n",
    "        image_un.append(image)\n",
    "\n",
    "        shape.append(image.shape)\n",
    "\n",
    "    # Sum the shape\n",
    "    shape_sum = tuple(map(sum, tuple(zip(*shape)))) \n",
    "    shape_median = tuple(np.percentile(dim, 50) for dim in zip(*shape))\n",
    "    shape_per25 = tuple(np.percentile(dim, 25) for dim in zip(*shape))\n",
    "    shape_per75 = tuple(np.percentile(dim, 75) for dim in zip(*shape))\n",
    "    shape_per90 = tuple(np.percentile(dim, 90) for dim in zip(*shape))\n",
    "    shape_min = tuple(map(min, tuple(zip(*shape))))\n",
    "    shape_max = tuple(map(max, tuple(zip(*shape))))\n",
    "\n",
    "    # Calcualting shape average\n",
    "    shape_avg = tuple( i // len(shape) for i in shape_sum)\n",
    "\n",
    "    # Print results\n",
    "    print(f'The average dimensions for images in the {key} folder is {shape_avg}')\n",
    "    print(f'The maximum dimensions for images in the {key} folder is {shape_max}')\n",
    "    print(f'The mimimum dimensions for images in the {key} folder is {shape_min}')\n",
    "    print(f'The median dimensions for images in the {key} folder is {shape_median}')\n",
    "    print(f'The 25th percentile dimensions for images in the {key} folder is {shape_per25}')\n",
    "    print(f'The 75th percentile dimensions for images in the {key} folder is {shape_per75}')\n",
    "    print(f'The 90th percentile dimensions for images in the {key} folder is {shape_per90}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba67fd6-1066-4802-bdfa-17ca3103f0da",
   "metadata": {},
   "source": [
    "### Defining the image resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fc5ea2-236e-40e6-b9a4-f4aa6739ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e369813a-6689-4b1b-965a-6f3d3b9c0730",
   "metadata": {},
   "source": [
    "### Image Augmentation and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7e2982-5b28-4d9e-8466-c5523136a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen = ImageDataGenerator(rescale=1./255, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68836bf2-6ab1-49ef-82ff-6af7a6c4906c",
   "metadata": {},
   "source": [
    "### Apply Image augmentation and scaling to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3d69ed-9720-45fc-9b15-8d9edc632014",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = img_gen.flow_from_directory(data_dir,\n",
    "                                         target_size=res, batch_size=64, class_mode='binary',\n",
    "                                         shuffle=True,subset='training')\n",
    "\n",
    "train_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055fe509-0c5c-4fd3-a4e1-2edbd6ddf250",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = img_gen.flow_from_directory(data_dir,\n",
    "                                        target_size=res,batch_size=1, shuffle=False,\n",
    "                                        class_mode='binary',\n",
    "                                        subset='validation')\n",
    "\n",
    "val_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbff6767-c009-4f5b-b882-d3f00f005909",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = img_gen.flow_from_directory(data_dir,\n",
    "                                        target_size=res, batch_size=1, shuffle=False,\n",
    "                                        class_mode='binary',\n",
    "                                        subset='validation')\n",
    "\n",
    "test_data.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b28e48-5e5b-4576-be11-12a7adb23008",
   "metadata": {},
   "source": [
    "### Load model if it already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c275ea8a-291e-4f8a-b62c-8db449b288cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T16:20:58.321715Z",
     "iopub.status.busy": "2025-03-21T16:20:58.321121Z",
     "iopub.status.idle": "2025-03-21T16:20:58.338327Z",
     "shell.execute_reply": "2025-03-21T16:20:58.331210Z",
     "shell.execute_reply.started": "2025-03-21T16:20:58.321665Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.path.exists(model_file) :\n",
    "    cnn = joblib.load('../model/CNN.joblib')\n",
    "    scaler = joblib.load('../model/CNN_scaler.joblib')\n",
    "    print('Model exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95e1da0-fbb6-4340-91de-439cab57aaaa",
   "metadata": {},
   "source": [
    "### Define model if it does not already exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b21ad2c-6a4a-4a71-b7fb-7044f1c7ce1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T16:23:29.093420Z",
     "iopub.status.busy": "2025-03-21T16:23:29.092858Z",
     "iopub.status.idle": "2025-03-21T16:23:29.110537Z",
     "shell.execute_reply": "2025-03-21T16:23:29.109173Z",
     "shell.execute_reply.started": "2025-03-21T16:23:29.093375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model does not exists\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(model_file) :\n",
    "    print('Model does not exists')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf89259-5407-449b-a92b-46902d5e665e",
   "metadata": {},
   "source": [
    "### Train the model on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc12a93-b73c-4f24-a9c0-8937d5607545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4427a733-1889-4c92-a8b6-abedd90760f4",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3e7930-7d31-4643-8487-62ed7d5f77e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(cnn, \"../model/CNN.joblib\")\n",
    "joblib.dump(scaler, \"../model/CNN_scaler.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "graph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
